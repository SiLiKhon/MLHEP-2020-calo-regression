{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "uqpo-u3SJ6BL"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "t8eHlqdVJ0oP"
   },
   "source": [
    "Let's have a look at the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "input_data_path = Path(os.environ.get('INPUT_DATA_PATH', '.'))\n",
    "output_data_path = Path(os.environ.get('OUTPUT_DATA_PATH', '.'))\n",
    "\n",
    "train_file = str(input_data_path / \"data_train.npz\")\n",
    "test_file = str(input_data_path / \"data_test.npz\")\n",
    "prediction_file = str(output_data_path / \"data_test_prediction.npz\")\n",
    "\n",
    "\n",
    "if not (os.path.isfile(train_file) and\n",
    "        os.path.isfile(test_file)):\n",
    "    if not os.path.isfile(\"input_public_data.zip\"):\n",
    "        !wget https://codalab.coresearch.club/my/datasets/download/37304c34-1d4a-4f43-bcb2-1fdeb37c5cba -O input_public_data.zip\n",
    "    !unzip -n input_public_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PnwQTWoUuV1B"
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KVTLnfHsvH29"
   },
   "outputs": [
   ],
   "source": [
    "data_real = np.load(train_file, allow_pickle=True)\n",
    "\n",
    "# This is the calorimeter response:\n",
    "energy = data_real['EnergyDeposit']\n",
    "\n",
    "# These are the quantities we want to predict\n",
    "momentum = data_real['ParticleMomentum'][:,:2]\n",
    "coordinate = data_real['ParticlePoint'][:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "LxBkEZ-HGGkY",
    "outputId": "d8886772-a886-4934-e04a-05d9b96ef04e"
   },
   "outputs": [
   ],
   "source": [
    "print('energy.shape:', energy.shape)\n",
    "print('momentum.shape:', momentum.shape)\n",
    "print('coordinate.shape:', coordinate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KtNiLcfTKZAT"
   },
   "source": [
    "So, we have images of 30x30 pixels and we want to predict 4 numbers for each of them: x, y, px and py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "7Z9d8ZfTKmkS"
   },
   "source": [
    "Let's have a look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qo0cQCrBFkhs"
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "adq1QO8LFqYN",
    "outputId": "feb34f3e-3fcd-445c-86bc-171d87e438d8"
   },
   "outputs": [
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.subplot(221)\n",
    "plt.imshow(energy[5])\n",
    "plt.subplot(222)\n",
    "plt.imshow(energy[50])\n",
    "plt.subplot(223)\n",
    "plt.imshow(energy[500])\n",
    "plt.subplot(224)\n",
    "plt.imshow(energy[5000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "IXXwCOt1KvKN"
   },
   "source": [
    "It's also worth knowing how the targets are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "scFXIWjZwAFq",
    "outputId": "3ddc84f3-9764-4c35-bfdc-fb7dd4f05954"
   },
   "outputs": [
   ],
   "source": [
    "plt.scatter(*momentum.T, s=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "nIYBOK8HGAbW",
    "outputId": "5a5e05cd-4c84-4442-cfea-4d7835de08e1"
   },
   "outputs": [
   ],
   "source": [
    "plt.scatter(*coordinate.T, s=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "uAeQH_sQK8IQ"
   },
   "source": [
    "Naive approach: can we predict the coordinates from the center of mass position of the calorimeter response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3mt3FiINGqXz",
    "outputId": "b5104903-df1c-42d7-d5dd-2774bd9658bb"
   },
   "outputs": [
   ],
   "source": [
    "energy_density = energy / energy.sum(axis=(1, 2), keepdims=True)\n",
    "\n",
    "cell_coords = np.stack([*np.meshgrid(\n",
    "    np.arange(energy.shape[1]),\n",
    "    np.arange(energy.shape[2])\n",
    ")], axis=-1)[None,...]\n",
    "\n",
    "center_of_mass = (energy_density[...,None] * cell_coords).sum(axis=(1, 2))\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(121)\n",
    "plt.scatter(coordinate[:,0], center_of_mass[:,0], s=5)\n",
    "plt.subplot(122)\n",
    "plt.scatter(coordinate[:,1], center_of_mass[:,1], s=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "YUoqUZHCLf3i"
   },
   "source": [
    "Looks like the correlation isn't too strong. Maybe higher moments would give us a better picture, but we'll leave such experiments to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "rTLaOd8rNULd"
   },
   "source": [
    "# Example solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "c7jiMXIHynma"
   },
   "outputs": [
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ZBuDIFV-N-Vp",
    "outputId": "ac3e10a1-1a8a-4f1b-919c-08804970bbaf"
   },
   "outputs": [
   ],
   "source": [
    "X = energy[:,None,...] # adding Channels dimension\n",
    "Y = np.concatenate([coordinate, momentum], axis=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "E4fWo7mawEs5"
   },
   "outputs": [
   ],
   "source": [
    "def make_torch_dataset(X, Y, batch_size, shuffle=True):\n",
    "    X = torch.tensor(X).float()\n",
    "    Y = torch.tensor(Y).float()\n",
    "    ds = utils.TensorDataset(X, Y)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        ds, batch_size=batch_size,\n",
    "        pin_memory=True, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "ds_train = make_torch_dataset(X_train, Y_train, BATCH_SIZE)\n",
    "ds_val = make_torch_dataset(X_val, Y_val, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tdlmdZrMywul"
   },
   "outputs": [
   ],
   "source": [
    "# Disclaimer: this might not be the best architecture for the task\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=3,\n",
    "                               kernel_size=7)\n",
    "        self.pool = nn.MaxPool2d((4, 4))\n",
    "        self.conv2 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=8,\n",
    "                               kernel_size=4)\n",
    "\n",
    "        self.fc1 = nn.Linear(3 * 3 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2 + 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(len(x), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MQbp_fgby8_d",
    "outputId": "30ef6c88-0b98-405a-fc87-dc782b39b767"
   },
   "outputs": [
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KSBfriTgy6OO"
   },
   "outputs": [
   ],
   "source": [
    "regressor = Regressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PFhD7tURzCQN"
   },
   "outputs": [
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "opt = optim.Adam(regressor.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "QYyOjzMizUYf"
   },
   "outputs": [
   ],
   "source": [
    "def metric_relative_mse(y_true, y_pred):\n",
    "    return (\n",
    "        (y_true - y_pred).pow(2).mean(dim=0) / y_true.pow(2).mean(dim=0)\n",
    "    )\n",
    "\n",
    "def metric_relative_mse_total(y_true, y_pred):\n",
    "    return metric_relative_mse(y_true, y_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "-q8L1r1FzgFh"
   },
   "outputs": [
   ],
   "source": [
    "# Disclaimer: this might not be the best loss function for this task.\n",
    "loss_fn = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KaDRrfUezvkr"
   },
   "outputs": [
   ],
   "source": [
    "def run_training(epochs=5):\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    metrics_train = []\n",
    "    metrics_val = []\n",
    "    per_component_metrics_train = []\n",
    "    per_component_metrics_val = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batch_X, batch_Y in ds_train:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "            pred = regressor(batch_X)\n",
    "            loss = loss_fn(pred, batch_Y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            losses_train.append(loss.item())\n",
    "            metrics_train.append(\n",
    "                metric_relative_mse_total(batch_Y, pred).item()\n",
    "            )\n",
    "\n",
    "            per_component_metrics_train.append(\n",
    "                metric_relative_mse(batch_Y, pred).detach().cpu().numpy()\n",
    "            )\n",
    "\n",
    "        avg_loss, avg_metrics, avg_per_component_metrics = [], [], []\n",
    "        for batch_X, batch_Y in ds_val:\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "            pred = regressor(batch_X)\n",
    "            loss = loss_fn(pred, batch_Y)\n",
    "\n",
    "            avg_loss.append(loss.item())\n",
    "            avg_metrics.append(\n",
    "                metric_relative_mse_total(batch_Y, pred).item()\n",
    "            )\n",
    "            avg_per_component_metrics.append(\n",
    "                metric_relative_mse(batch_Y, pred).detach().cpu().numpy()\n",
    "            )\n",
    "        losses_val.append(np.mean(avg_loss))\n",
    "        metrics_val.append(np.mean(avg_metrics))\n",
    "        per_component_metrics_val.append(\n",
    "            np.mean(avg_per_component_metrics, axis=0)\n",
    "        )\n",
    "\n",
    "\n",
    "        clear_output()\n",
    "        plt.figure(figsize=(18, 4.5))\n",
    "\n",
    "        plt.subplot(131)\n",
    "\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(losses_train, label='train')\n",
    "        plt.plot(\n",
    "            np.linspace(0, len(losses_train), len(losses_val), endpoint=False),\n",
    "            losses_val, label='val'\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(132)\n",
    "\n",
    "        plt.title(\"Metric (per component)\")\n",
    "        ms_train = np.array(per_component_metrics_train).T\n",
    "        ms_val = np.array(per_component_metrics_val).T\n",
    "        for i, (m_train, m_val, color) in enumerate(zip(ms_train,\n",
    "                                                        ms_val,\n",
    "                                                        plt.rcParams['axes.prop_cycle'])):\n",
    "            plt.plot(m_train, label=f'train (component {i})', c=color['color'])\n",
    "            plt.plot(\n",
    "                np.linspace(0, len(m_train), len(m_val), endpoint=False),\n",
    "                m_val, '--', label=f'val (component {i})', c=color['color']\n",
    "            )\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(133)\n",
    "\n",
    "        plt.title(\"Metric (total)\")\n",
    "        plt.plot(metrics_train, label='train')\n",
    "        plt.plot(\n",
    "            np.linspace(0, len(metrics_train), len(metrics_val), endpoint=False),\n",
    "            metrics_val, label='val'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "K7WO5pPCzzdk",
    "outputId": "953da882-8ce2-480e-b527-e179705f2abe"
   },
   "outputs": [
   ],
   "source": [
    "run_training(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "5bN3HPY10DAV"
   },
   "outputs": [
   ],
   "source": [
    "data_test = np.load(test_file, allow_pickle=True)\n",
    "X_test = data_test['EnergyDeposit'][:,None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "uEUeTOuI120h"
   },
   "outputs": [
   ],
   "source": [
    "prediction_test = regressor(torch.tensor(X_test, device=device).float()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jKDDvcBr1-Sa"
   },
   "outputs": [
   ],
   "source": [
    "coordinate_test, momentum_test = (\n",
    "    prediction_test.detach().numpy()[:, :2],\n",
    "    prediction_test.detach().numpy()[:, 2:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "QUGKOcHl2HMj"
   },
   "outputs": [
   ],
   "source": [
    "np.savez_compressed(prediction_file,\n",
    "                    ParticlePoint=coordinate_test,\n",
    "                    ParticleMomentum=momentum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JNs5peky2MRc"
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CompetitionStartingKit.ipynb",
   "provenance": [
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
